{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GazeCapture.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "u28VYTc30G27",
        "colab_type": "code",
        "outputId": "2b9ccd52-cf10-4a58-fcf2-df02096cba06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        }
      },
      "source": [
        "import math, shutil, os, time, argparse, json, re, sys\n",
        "import numpy as np\n",
        "import scipy.io as sio\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "'''\n",
        "Prepares the GazeCapture dataset for use with the pytorch code. Crops images, compiles JSONs into metadata.mat\n",
        "Author: Petr Kellnhofer ( pkel_lnho (at) gmai_l.com // remove underscores and spaces), 2018. \n",
        "Website: http://gazecapture.csail.mit.edu/\n",
        "Cite:\n",
        "Eye Tracking for Everyone\n",
        "K.Krafka*, A. Khosla*, P. Kellnhofer, H. Kannan, S. Bhandarkar, W. Matusik and A. Torralba\n",
        "IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016\n",
        "@inproceedings{cvpr2016_gazecapture,\n",
        "Author = {Kyle Krafka and Aditya Khosla and Petr Kellnhofer and Harini Kannan and Suchendra Bhandarkar and Wojciech Matusik and Antonio Torralba},\n",
        "Title = {Eye Tracking for Everyone},\n",
        "Year = {2016},\n",
        "Booktitle = {IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}\n",
        "}\n",
        "'''\n",
        "\n",
        "parser = argparse.ArgumentParser(description='iTracker-pytorch-PrepareDataset.')\n",
        "parser.add_argument('--dataset_path', help=\"Path to extracted files. It should have folders called '%%05d' in it.\")\n",
        "parser.add_argument('--output_path', default=None, help=\"Where to write the output. Can be the same as dataset_path if you wish (=default).\")\n",
        "args = parser.parse_args()\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    if args.output_path is None:\n",
        "        args.output_path = args.dataset_path\n",
        "    \n",
        "    if args.dataset_path is None or not os.path.isdir(args.dataset_path):\n",
        "        raise RuntimeError('No such dataset folder %s!' % args.dataset_path)\n",
        "\n",
        "    preparePath(args.output_path)\n",
        "\n",
        "    # list recordings\n",
        "    recordings = os.listdir(args.dataset_path)\n",
        "    recordings = np.array(recordings, np.object)\n",
        "    recordings = recordings[[os.path.isdir(os.path.join(args.dataset_path, r)) for r in recordings]]\n",
        "    recordings.sort()\n",
        "\n",
        "    # Output structure\n",
        "    meta = {\n",
        "        'labelRecNum': [],\n",
        "        'frameIndex': [],\n",
        "        'labelDotXCam': [],\n",
        "        'labelDotYCam': [],\n",
        "        'labelFaceGrid': [],\n",
        "    }\n",
        "\n",
        "    for i,recording in enumerate(recordings):\n",
        "        print('[%d/%d] Processing recording %s (%.2f%%)' % (i, len(recordings), recording, i / len(recordings) * 100))\n",
        "        recDir = os.path.join(args.dataset_path, recording)\n",
        "        recDirOut = os.path.join(args.output_path, recording)\n",
        "\n",
        "        # Read JSONs\n",
        "        appleFace = readJson(os.path.join(recDir, 'appleFace.json'))\n",
        "        if appleFace is None:\n",
        "            continue\n",
        "        appleLeftEye = readJson(os.path.join(recDir, 'appleLeftEye.json'))\n",
        "        if appleLeftEye is None:\n",
        "            continue\n",
        "        appleRightEye = readJson(os.path.join(recDir, 'appleRightEye.json'))\n",
        "        if appleRightEye is None:\n",
        "            continue\n",
        "        dotInfo = readJson(os.path.join(recDir, 'dotInfo.json'))\n",
        "        if dotInfo is None:\n",
        "            continue\n",
        "        faceGrid = readJson(os.path.join(recDir, 'faceGrid.json'))\n",
        "        if faceGrid is None:\n",
        "            continue\n",
        "        frames = readJson(os.path.join(recDir, 'frames.json'))\n",
        "        if frames is None:\n",
        "            continue\n",
        "        # info = readJson(os.path.join(recDir, 'info.json'))\n",
        "        # if info is None:\n",
        "        #     continue\n",
        "        # screen = readJson(os.path.join(recDir, 'screen.json'))\n",
        "        # if screen is None:\n",
        "        #     continue\n",
        "\n",
        "        facePath = preparePath(os.path.join(recDirOut, 'appleFace'))\n",
        "        leftEyePath = preparePath(os.path.join(recDirOut, 'appleLeftEye'))\n",
        "        rightEyePath = preparePath(os.path.join(recDirOut, 'appleRightEye'))\n",
        "\n",
        "        # Preprocess\n",
        "        allValid = np.logical_and(np.logical_and(appleFace['IsValid'], appleLeftEye['IsValid']), np.logical_and(appleRightEye['IsValid'], faceGrid['IsValid']))\n",
        "        if not np.any(allValid):\n",
        "            continue\n",
        "\n",
        "        frames = np.array([int(re.match('(\\d{5})\\.jpg$', x).group(1)) for x in frames])\n",
        "\n",
        "        bboxFromJson = lambda data: np.stack((data['X'], data['Y'], data['W'],data['H']), axis=1).astype(int)\n",
        "        faceBbox = bboxFromJson(appleFace) + [-1,-1,1,1] # for compatibility with matlab code\n",
        "        leftEyeBbox = bboxFromJson(appleLeftEye) + [0,-1,0,0]\n",
        "        rightEyeBbox = bboxFromJson(appleRightEye) + [0,-1,0,0]\n",
        "        leftEyeBbox[:,:2] += faceBbox[:,:2] # relative to face\n",
        "        rightEyeBbox[:,:2] += faceBbox[:,:2]\n",
        "        faceGridBbox = bboxFromJson(faceGrid)\n",
        "\n",
        "\n",
        "        for j,frame in enumerate(frames):\n",
        "            # Can we use it?\n",
        "            if not allValid[j]:\n",
        "                continue\n",
        "\n",
        "            # Load image\n",
        "            imgFile = os.path.join(recDir, 'frames', '%05d.jpg' % frame)\n",
        "            if not os.path.isfile(imgFile):\n",
        "                logError('Warning: Could not read image file %s!' % imgFile)\n",
        "                continue\n",
        "            img = Image.open(imgFile)        \n",
        "            if img is None:\n",
        "                logError('Warning: Could not read image file %s!' % imgFile)\n",
        "                continue\n",
        "            img = np.array(img.convert('RGB'))\n",
        "\n",
        "            # Crop images\n",
        "            imFace = cropImage(img, faceBbox[j,:])\n",
        "            imEyeL = cropImage(img, leftEyeBbox[j,:])\n",
        "            imEyeR = cropImage(img, rightEyeBbox[j,:])\n",
        "\n",
        "            # Save images\n",
        "            Image.fromarray(imFace).save(os.path.join(facePath, '%05d.jpg' % frame), quality=95)\n",
        "            Image.fromarray(imEyeL).save(os.path.join(leftEyePath, '%05d.jpg' % frame), quality=95)\n",
        "            Image.fromarray(imEyeR).save(os.path.join(rightEyePath, '%05d.jpg' % frame), quality=95)\n",
        "\n",
        "            # Collect metadata\n",
        "            meta['labelRecNum'] += [int(recording)]\n",
        "            meta['frameIndex'] += [frame]\n",
        "            meta['labelDotXCam'] += [dotInfo['XCam'][j]]\n",
        "            meta['labelDotYCam'] += [dotInfo['YCam'][j]]\n",
        "            meta['labelFaceGrid'] += [faceGridBbox[j,:]]\n",
        "\n",
        "    \n",
        "    # Integrate\n",
        "    meta['labelRecNum'] = np.stack(meta['labelRecNum'], axis = 0).astype(np.int16)\n",
        "    meta['frameIndex'] = np.stack(meta['frameIndex'], axis = 0).astype(np.int32)\n",
        "    meta['labelDotXCam'] = np.stack(meta['labelDotXCam'], axis = 0)\n",
        "    meta['labelDotYCam'] = np.stack(meta['labelDotYCam'], axis = 0)\n",
        "    meta['labelFaceGrid'] = np.stack(meta['labelFaceGrid'], axis = 0).astype(np.uint8)\n",
        "\n",
        "    # Load reference metadata\n",
        "    print('Will compare to the reference GitHub dataset metadata.mat...')\n",
        "    reference = sio.loadmat('./reference_metadata.mat', struct_as_record=False) \n",
        "    reference['labelRecNum'] = reference['labelRecNum'].flatten()\n",
        "    reference['frameIndex'] = reference['frameIndex'].flatten()\n",
        "    reference['labelDotXCam'] = reference['labelDotXCam'].flatten()\n",
        "    reference['labelDotYCam'] = reference['labelDotYCam'].flatten()\n",
        "    reference['labelTrain'] = reference['labelTrain'].flatten()\n",
        "    reference['labelVal'] = reference['labelVal'].flatten()\n",
        "    reference['labelTest'] = reference['labelTest'].flatten()\n",
        "\n",
        "    # Find mapping\n",
        "    mKey = np.array(['%05d_%05d' % (rec, frame) for rec, frame in zip(meta['labelRecNum'], meta['frameIndex'])], np.object)\n",
        "    rKey = np.array(['%05d_%05d' % (rec, frame) for rec, frame in zip(reference['labelRecNum'], reference['frameIndex'])], np.object)\n",
        "    mIndex = {k: i for i,k in enumerate(mKey)}\n",
        "    rIndex = {k: i for i,k in enumerate(rKey)}\n",
        "    mToR = np.zeros((len(mKey,)),int) - 1\n",
        "    for i,k in enumerate(mKey):\n",
        "        if k in rIndex:\n",
        "            mToR[i] = rIndex[k]\n",
        "        else:\n",
        "            logError('Did not find rec_frame %s from the new dataset in the reference dataset!' % k)\n",
        "    rToM = np.zeros((len(rKey,)),int) - 1\n",
        "    for i,k in enumerate(rKey):\n",
        "        if k in mIndex:\n",
        "            rToM[i] = mIndex[k]\n",
        "        else:\n",
        "            logError('Did not find rec_frame %s from the reference dataset in the new dataset!' % k, critical = False)\n",
        "            #break\n",
        "\n",
        "    # Copy split from reference\n",
        "    meta['labelTrain'] = np.zeros((len(meta['labelRecNum'],)),np.bool)\n",
        "    meta['labelVal'] = np.ones((len(meta['labelRecNum'],)),np.bool) # default choice\n",
        "    meta['labelTest'] = np.zeros((len(meta['labelRecNum'],)),np.bool)\n",
        "\n",
        "    validMappingMask = mToR >= 0\n",
        "    meta['labelTrain'][validMappingMask] = reference['labelTrain'][mToR[validMappingMask]]\n",
        "    meta['labelVal'][validMappingMask] = reference['labelVal'][mToR[validMappingMask]]\n",
        "    meta['labelTest'][validMappingMask] = reference['labelTest'][mToR[validMappingMask]]\n",
        "\n",
        "    # Write out metadata\n",
        "    metaFile = os.path.join(args.output_path, 'metadata.mat')\n",
        "    print('Writing out the metadata.mat to %s...' % metaFile)\n",
        "    sio.savemat(metaFile, meta)\n",
        "    \n",
        "    # Statistics\n",
        "    nMissing = np.sum(rToM < 0)\n",
        "    nExtra = np.sum(mToR < 0)\n",
        "    totalMatch = len(mKey) == len(rKey) and np.all(np.equal(mKey, rKey))\n",
        "    print('======================\\n\\tSummary\\n======================')    \n",
        "    print('Total added %d frames from %d recordings.' % (len(meta['frameIndex']), len(np.unique(meta['labelRecNum']))))\n",
        "    if nMissing > 0:\n",
        "        print('There are %d frames missing in the new dataset. This may affect the results. Check the log to see which files are missing.' % nMissing)\n",
        "    else:\n",
        "        print('There are no missing files.')\n",
        "    if nExtra > 0:\n",
        "        print('There are %d extra frames in the new dataset. This is generally ok as they were marked for validation split only.' % nExtra)\n",
        "    else:\n",
        "        print('There are no extra files that were not in the reference dataset.')\n",
        "    if totalMatch:\n",
        "        print('The new metadata.mat is an exact match to the reference from GitHub (including ordering)')\n",
        "\n",
        "    #import pdb; pdb.set_trace()\n",
        "    input(\"Press Enter to continue...\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def readJson(filename):\n",
        "    if not os.path.isfile(filename):\n",
        "        logError('Warning: No such file %s!' % filename)\n",
        "        return None\n",
        "\n",
        "    with open(filename) as f:\n",
        "        try:\n",
        "            data = json.load(f)\n",
        "        except:\n",
        "            data = None\n",
        "\n",
        "    if data is None:\n",
        "        logError('Warning: Could not read file %s!' % filename)\n",
        "        return None\n",
        "\n",
        "    return data\n",
        "\n",
        "def preparePath(path, clear = False):\n",
        "    if not os.path.isdir(path):\n",
        "        os.makedirs(path, 0o777)\n",
        "    if clear:\n",
        "        files = os.listdir(path)\n",
        "        for f in files:\n",
        "            fPath = os.path.join(path, f)\n",
        "            if os.path.isdir(fPath):\n",
        "                shutil.rmtree(fPath)\n",
        "            else:\n",
        "                os.remove(fPath)\n",
        "\n",
        "    return path\n",
        "\n",
        "def logError(msg, critical = False):\n",
        "    print(msg)\n",
        "    if critical:\n",
        "        sys.exit(1)\n",
        "\n",
        "\n",
        "def cropImage(img, bbox):\n",
        "    bbox = np.array(bbox, int)\n",
        "\n",
        "    aSrc = np.maximum(bbox[:2], 0)\n",
        "    bSrc = np.minimum(bbox[:2] + bbox[2:], (img.shape[1], img.shape[0]))\n",
        "\n",
        "    aDst = aSrc - bbox[:2]\n",
        "    bDst = aDst + (bSrc - aSrc)\n",
        "\n",
        "    res = np.zeros((bbox[3], bbox[2], img.shape[2]), img.dtype)    \n",
        "    res[aDst[1]:bDst[1],aDst[0]:bDst[0],:] = img[aSrc[1]:bSrc[1],aSrc[0]:bSrc[0],:]\n",
        "\n",
        "    return res\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "    print('DONE')\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "usage: ipykernel_launcher.py [-h] [--dataset_path DATASET_PATH]\n",
            "                             [--output_path OUTPUT_PATH]\n",
            "ipykernel_launcher.py: error: unrecognized arguments: -f /root/.local/share/jupyter/runtime/kernel-d4320bfb-8b8e-4fde-ae10-bce6b4600d54.json\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
          ]
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6LGqBVWkKJU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gd2MSeffoMTL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}